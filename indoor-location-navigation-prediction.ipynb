{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#安裝module到kaggle環境\n!cp -r /kaggle/input/d/evanhsiao/indoor-location-navigation/* ./\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport json\nfrom io_f import read_data_file\nfrom main import calibrate_magnetic_wifi_ibeacon_to_position, extract_magnetic_strength, extract_wifi_rssi, extract_ibeacon_rssi, extract_wifi_count\nfrom compute_f import compute_step_positions\nfrom visualize_f import visualize_trajectory, visualize_heatmap\nimport compute_f\nimport visualize_f\nimport keras as k\nfrom keras import layers\nimport matplotlib.pyplot as plt\nnp.set_printoptions(suppress=True)\nnp.random.seed(1)\nfrom dataclasses import dataclass\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Functions\ndef test_data_to_test_x(ReadData):\n    '''\n    Retrive features from test data file to model\n    \n    Argument\n    ReadData: Object from read_data_file function; dtype ReadData object\n    \n    Return\n    test_x: A [features, sample#] matrix for model; dtype np.array\n    '''\n    acce_data = ReadData.acce\n    acce_uncali_data = ReadData.acce_uncali\n    gyro_data = ReadData.gyro\n    gyro_uncali_data = ReadData.gyro_uncali\n    magn_data = ReadData.magn\n    magn_uncali_data = ReadData.magn_uncali\n    ahrs_data = ReadData.ahrs\n    wifi_data = ReadData.wifi\n    ibeacon_data = ReadData.ibeacon\n    waypoint_data = ReadData.waypoint\n    \n    test_x = np.zeros(((acce_data.shape[1]-1)*3 + 1, acce_data.shape[0]))\n    for i in range(acce_data.shape[0]):\n        timestep = acce_data[i, 0]\n        acce = acce_data[i:i+1, 0:]\n        magn = magn_data[i:i+1, 1:]\n        ahrs = ahrs_data[i:i+1, 1:]\n        test_x[:, i:i+1] = np.concatenate((acce, magn, ahrs), axis = 1).T\n    return test_x\n    \n    \ndef location_sensor_filter(ReadData):\n    '''\n    Filter acce and magn data and reshape training data into shape:(features, samples) array; training label into shape:(locations, samples) array\n    \n    Arguments\n    ReadData: A object from txt file; dtype ReadData object\n    \n    Returns\n    data: A [features, sample#] matrix; dtype np.array\n    label: A [waypoints, samples#] matrix; dtype np.array\n    '''\n    acce_data = ReadData.acce\n    acce_uncali_data = ReadData.acce_uncali\n    gyro_data = ReadData.gyro\n    gyro_uncali_data = ReadData.gyro_uncali\n    magn_data = ReadData.magn\n    magn_uncali_data = ReadData.magn_uncali\n    ahrs_data = ReadData.ahrs\n    wifi_data = ReadData.wifi\n    ibeacon_data = ReadData.ibeacon\n    waypoint_data = ReadData.waypoint\n    \n    data = np.zeros(((acce_data.shape[1]-1)*3, acce_data.shape[0]))\n    label = np.zeros((2, acce_data.shape[0])) \n    locations = compute_step_positions(acce_data, ahrs_data, waypoint_data)\n    \n    for i in range(acce_data.shape[0]):\n        timestep = acce_data[i, 0]\n        acce = acce_data[i:i+1, 1:]\n        magn = magn_data[i:i+1, 1:]\n        ahrs = ahrs_data[i:i+1, 1:]\n        data[:, i:i+1] = np.concatenate((acce, magn, ahrs), axis = 1).T\n        if timestep < locations[-1, 0]:\n            index = np.where(locations[:, 0] > timestep)[0][0]\n            if index == 0:\n                upper_timestep = locations[1, 0]  \n                lower_timestep = locations[0, 0]\n                vector = locations[1, 1:] - locations[0, 1:]\n                adjust = (lower_timestep - timestep) / (upper_timestep - lower_timestep)\n                location = locations[0, 1:] - vector * adjust\n                label[:, i] = location.T                \n            else:\n                upper_timestep = locations[index, 0]  \n                lower_timestep = locations[index-1, 0]\n                vector = locations[index, 1:] - locations[index-1, 1:]\n                adjust = (timestep - lower_timestep) / (upper_timestep - lower_timestep)\n                location = locations[index-1, 1:] + vector * adjust\n                label[:, i] = location.T\n        else:\n            upper_timestep = locations[-1, 0]  \n            lower_timestep = locations[-2, 0]\n            vector = locations[-1, 1:] - locations[-2, 1:]\n            adjust = (timestep - upper_timestep) / (upper_timestep - lower_timestep)\n            location = locations[-1, 1:] + vector * adjust\n            label[:, i] = location.T            \n                \n    return data, label\n\ndef location_training(model, train_paths, epo=1):\n    '''\n    Fit model over all train set.\n    \n    Arguments\n    model: Customized Neural Network model; dtype k.model\n    train_paths: All training data file paths; dtype list\n    epo = Epoch# over all training set; dtype int\n    \n    Returns\n    model: A trained model to predict waypoint; dtype k.model\n    '''\n    for i in range(epo):\n        for step, path in enumerate(train_paths):\n            try:\n                path_data = read_data_file(path)\n                data, label = location_sensor_filter(path_data)\n                indices = np.random.permutation(data.shape[1])\n                data = data[:, indices]\n                label = label[:, indices]\n                dev_x = data[:, -100:]\n                dev_y = label[:, -100:]\n                train_x = data[:, :-100]\n                train_y = label[:, :-100]\n                history = model.fit(train_x.T, train_y.T, batch_size=64, epochs = epo+1, validation_data = (dev_x.T, dev_y.T), verbose=0, shuffle=True)\n                if step % 100 == 0:\n                    print(f'Training loss: {history.history[\"loss\"][0]}; Dev loss: {history.history[\"val_loss\"][0]} at step {step+1}.')\n            except:\n                print(f'Traing faile at {path}.')\n                continue\n    return model\n\ndef site_floor_bssid_rssi_dic(submission_site_paths, rssi_threshold = -75):\n    '''\n    Record max rssi of bssid of each site-floor into a {site: {floor: {bssid: rssi}}} dictionary from training set.\n    \n    Arguments\n    submission_site_paths: All paths in submission.csv file; dtype list\n    rssi_threshold: filter weak signal; dtype int\n    \n    Returns\n    max_rssi_dic: A {site: {floor: {bssid: rssi}}} dictionary which sites are needed in submission file; dtype dic\n    '''\n    max_rssi_dic = {}\n    for path in submission_site_paths:\n        path_list = path.split('/')\n        site = path_list[-3]\n        floor = path_list[-2]\n        path_data = read_data_file(path)\n        wifi_data = path_data.wifi\n        try:\n            for i in range(wifi_data.shape[0]):\n                bssid = wifi_data[i, 2] \n                rssi = wifi_data[i, 3]\n                if int(rssi) > rssi_threshold: #ignore weak signal\n                    if site not in max_rssi_dic.keys():\n                        max_rssi_dic[site] = {floor: {bssid: rssi}}\n                    else:\n                        if floor not in max_rssi_dic[site].keys():\n                            max_rssi_dic[site][floor] = {bssid: rssi}\n                        else:\n                            if bssid not in max_rssi_dic[site][floor].keys():\n                                max_rssi_dic[site][floor][bssid] = rssi\n                            else:\n                                if rssi > max_rssi_dic[site][floor][bssid]:\n                                    max_rssi_dic[site][floor][bssid] = rssi\n        except:\n            print(f'There is an abnormal file: {path}')\n    return max_rssi_dic\n\ndef floor_detect(ReadData, site, max_rssi_dic):\n    '''\n    Grade points for each floor to predict which floor on test path.\n    \n    Arguments\n    Readdata: path data in test set; dtype: Readdata\n    site: site of path data; dtype: str\n    max_rssi_dic: A {site: {floor: {bssid: rssi}}} dictionary from training set; dtype dic\n    \n    Returns\n    F: floor on test path; dtype int\n    '''\n    wifi_data = ReadData.wifi\n    floor_score = {}\n    F = 0\n    for floor in max_rssi_dic[site].keys():\n        floor_score[floor] = 0\n    for i in range(wifi_data.shape[0]):\n        test_bssid = wifi_data[i, 2]\n        test_rssi = wifi_data[i, 3]\n        for floor in max_rssi_dic[site].keys():\n            for bssid in max_rssi_dic[site][floor].keys():\n                if test_bssid == bssid and int(test_rssi) < int(max_rssi_dic[site][floor][bssid]):\n                    floor_score[floor] += 1\n                    break\n    for floor, score in floor_score.items():\n        if score == max(floor_score.values()):\n            F = floor\n            break   \n    if F == '1F' or F == 'F1':\n        F = 0\n    elif F == '2F' or F == 'F2':\n        F = 1\n    elif F == '3F' or F == 'F3':\n        F = 2\n    elif F == '4F' or F == 'F4':\n        F = 3\n    elif F == '5F' or F == 'F5':\n        F = 4\n    elif F == '6F' or F == 'F6':\n        F = 5\n    elif F == '7F' or F == 'F7':\n        F = 6\n    elif F == '8F' or F == 'F8':\n        F = 7\n    elif F == 'B1' or F == '1B':\n        F = -1\n    elif F == 'B2' or F == '2B':\n        F = -2\n    elif F == 'B3' or F == '3B':\n        F = -3\n    elif F == 'B4' or F == '4B':\n        F = -4\n    return F\n    \n         \n\ndef MSE(x_pred, y_pred, f_pred, x_true, y_true, f_true, p=15):\n    '''\n    A customized loss function to evaluate model performance\n    \n    Arguments\n    x_pred: x coordinate of waypoint; dtype np.array\n    y_pred: y coordinate of waypoint; dtype np.array\n    f_pred: floor of the site; dtype np.array\n    x_true: x coordinate of waypoint; dtype np.array\n    y_ture: y coordinate of waypoint; dtype np.array\n    z_true: floor of the site; dtype list()\n    p: a constant of floor penalty, set to 15 (always); dtype int\n\n    Returns\n    formula: value of loss function; dtype int\n    '''\n    \n    N = len(x_true)\n    formula = np.sqrt(np.power(x_pred - x_true, 2) + np.power(y_pred - y_true, 2))\n    formula = formula + p * np.abs(f_pred - f_true)\n    formula = formula.sum() / N\n    \n    return formula\ndef location_prediction_model(features):\n    '''\n    Simple Neural Network model.\n    \n    Arguments\n    features: Input feature numbers; dtype int\n    \n    Returns\n    model: A 3 hidden layers neural network model; dtype k.model\n    '''\n    model = k.Sequential(name='location_prediction')\n    model.add(k.Input(shape=(features, )))\n    model.add(layers.Dense(20, activation='relu'))\n    model.add(layers.Dense(10, activation='relu'))\n    model.add(layers.Dense(5, activation='relu'))\n    model.add(layers.Dense(2))\n    model.summary()  \n    return model\n\ndef submission_to_dic(csv):\n    '''\n    Return site dictionary {sites : {paths : [timesteps]}} for updating submission csv file.\n    \n    Arguments\n    csv: Submission.csv file; dtype pd.DataFrame\n    \n    Returns\n    site_dic: Dictiondary {sites : {paths : [timesteps]}}; dtype dic\n    '''\n    site_dic = {}\n    for site_path in csv['site_path_timestamp']:\n        site_path_list = site_path.split('_')\n        site = site_path_list[0]\n        path = site_path_list[1]\n        timestep = site_path_list[2]\n        \n        if site not in site_dic.keys():\n            site_dic[site] = {path: [timestep]}\n        else:\n            if path not in site_dic[site].keys():\n                site_dic[site][path] = [timestep]\n            else:\n                site_dic[site][path].append(timestep)\n    return site_dic\ndef submission_to_submission_paths(site_dic):\n    '''\n    Retrive paths where in submission.csv from train paths.\n    \n    Arguments\n    site_dic: A {sites: {path: timestep}} dictionary from submission; dtype dic\n    \n    Returns\n    submission_paths: paths where in submission.csv in training set; dtype list\n    '''\n    submission_paths = []\n    for site in site_dic.keys():\n        submission_paths += glob.glob(f'../input/indoor-location-navigation/train/{site}/*/*')\n    return submission_paths","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#視覺化compute_step_positions function\npath = f'../input/indoor-location-navigation/train/5a0546857ecc773753327266/B1/5e15730aa280850006f3d005.txt'\n#read_data_file會將檔案路徑(path)回傳ReadData object，包含屬性\n#TYPE_ACCELEROMETER: acce dtype np.array\n#TYPE_ACCELEROMETER_UNCALIBRATED: acce_uncali dtype np.array\n#TYPE_GYROSCOPE: gyro dtype np.array\n#TYPE_GYROSCOPE_UNCALIBRATED: gyro_uncali dtype np.array\n#TYPE_MAGNETIC_FIELD: magn \n#TYPE_MAGNETIC_FIELD_UNCALIBRATED: magn_uncali dtype np.array\n#TYPE_ROTATION_VECTOR: ahrs dtype np.array\n#TYPE_WIFI: wifi dtype np.array\n#TYPE_BEACON: ibeacon dtype np.array\n#TYPE_WAYPOINT: waypoint dtype np.array\n#範例如下輸出前五筆TYPE_ACCELEROMETER [timestep, x, y, z]\nexample = read_data_file(path)\npositions = compute_step_positions(example.acce, example.ahrs, example.waypoint)\ntest_waypoint = np.concatenate((example.waypoint[0:1], example.waypoint[-1:]), axis=0)\ntest_positions = compute_step_positions(example.acce, example.ahrs, test_waypoint)\nprint(f'Positions shape: {positions.shape}')\n#紅點為example中貼上標籤的waypoint\n#藍點為利用compute_step_positions function計算waypoint label之間移動的位置\n#綠點為waypoint label為第一筆和最後一筆，可以發現誤差會愈來愈大，直到最後收斂到最後一筆waypoint\nplt.figure(figsize=(16, 6))\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.scatter(positions[:, 1], positions[:, 2], color = 'blue')\nplt.scatter(test_positions[:, 1], test_positions[:, 2], color = 'green', marker='*')\nplt.scatter(example.waypoint[:, 1], example.waypoint[:, 2], color = 'red')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_waypoint.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#視覺化site: 5a0546857ecc773753327266, floor:B1的圖面\nfile_path = f'../input/indoor-location-navigation/train/5a0546857ecc773753327266/B1/5e15730aa280850006f3d005.txt'\nsite = file_path.split('/')[-3]\nfloor = file_path.split('/')[-2]\npath_id = file_path.split('/')[-1][:-4]\nfloor_info_filename = f'../input/indoor-location-navigation/metadata/{site}/{floor}/floor_info.json'\nfloor_plan_filename = f'../input/indoor-location-navigation/metadata/{site}/{floor}/floor_image.png'\nwith open(floor_info_filename) as f:\n    floor_info = json.load(f)\nwidth_meter = floor_info[\"map_info\"][\"width\"]\nheight_meter = floor_info[\"map_info\"][\"height\"]\npath_data = read_data_file(file_path)\nprint('Visualizing ground truth positions...')\nfig = visualize_trajectory(path_data.waypoint[:, 1:3], floor_plan_filename, width_meter, height_meter, title=path_id, show=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#讀取資料以視覺化更多資訊\nprint('Visualizing more information...')\nfile_paths = glob.glob('../input/indoor-location-navigation/train/5a0546857ecc773753327266/B1/*')\nmwi_datas = calibrate_magnetic_wifi_ibeacon_to_position(file_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mwi_datas[(106.67530172033818, 162.3157427483535)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#視覺化site: 5a0546857ecc773753327266, floor:B1 所有training set內收集的路徑\nstep_positions = np.array(list(mwi_datas.keys()))\nfig2 = visualize_trajectory(step_positions, floor_plan_filename, width_meter, height_meter, mode='markers', title='Step Position', show=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#視覺化site: 5a0546857ecc773753327266, floor:B1 所有training set內收集的磁場強度\nmagnetic_strength = extract_magnetic_strength(mwi_datas)\nheat_positions = np.array(list(magnetic_strength.keys()))\nheat_values = np.array(list(magnetic_strength.values()))\nfig3 = visualize_heatmap(heat_positions, heat_values, floor_plan_filename, width_meter, height_meter, colorbar_title='mu tesla', title='Magnetic Strength', show=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#視覺化site: 5a0546857ecc773753327266, floor:B1 所有training set內收集的wifi_id: rssi強度\nwifi_rssi = extract_wifi_rssi(mwi_datas)\nprint(f'This floor has {len(wifi_rssi.keys())} wifi aps')\nten_wifi_bssids = list(wifi_rssi.keys())[0:10]\nprint('Example 10 wifi ap bssids:\\n')\nfor bssid in ten_wifi_bssids:\n    print(bssid)\n#target_wifi = input(f\"Please input target wifi ap bssid:\\n\")\ntarget_wifi = '0b64e537cc3d1818ec46f94f8dc14043a98d0089'\n# target_wifi = '1e:74:9c:a7:b2:e4'\nheat_positions = np.array(list(wifi_rssi[target_wifi].keys()))\nheat_values = np.array(list(wifi_rssi[target_wifi].values()))[:, 0]\nfig4 = visualize_heatmap(heat_positions, heat_values, floor_plan_filename, width_meter, height_meter, colorbar_title='dBm', title=f'Wifi: {target_wifi} RSSI', show=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = '../input/indoor-location-navigation/test/00ff0c9a71cc37a2ebdd0f05.txt'\ntest_data = read_data_file(test_path)\nmax_rssi = max([int(i) for i in test_data.wifi[:, 3]])\nindex = list(test_data.wifi[:, 3]).index(str(max_rssi))\nbssid = test_data.wifi[index][2]\nwifi_rssi_max_test = {}\nfor bssid, dic in wifi_rssi.items():\n    max_rssi = max([array[0] for array in dic.values()])\n    for waypoint, array in dic.items():\n        if array[0] == max_rssi:\n            wifi_rssi_max_test[bssid] = waypoint\n            break\nwifi_rssi_max_test.keys()\n#找最近的","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#視覺化site: 5a0546857ecc773753327266, floor:B1 所有training set內收集的ibeacon_id: rssi強度\nibeacon_rssi = extract_ibeacon_rssi(mwi_datas)\nprint(f'This floor has {len(ibeacon_rssi.keys())} ibeacons')\nten_ibeacon_ummids = list(ibeacon_rssi.keys())[0:10]\nprint('Example 10 ibeacon UUID_MajorID_MinorIDs:\\n')\nfor ummid in ten_ibeacon_ummids:\n    print(ummid)\n#target_ibeacon = input(f\"Please input target ibeacon UUID_MajorID_MinorID:\\n\")\ntarget_ibeacon = '89cb11b04122cef23388b0da06bd426c1f48a9b5_cfc84f0752adc96b489f71195d91a946c5f6d3e8_8159618423dfa22f1ca0b62543e2f18eef630ce8'\n# target_ibeacon = 'FDA50693-A4E2-4FB1-AFCF-C6EB07647825_10073_61418'\nheat_positions = np.array(list(ibeacon_rssi[target_ibeacon].keys()))\nheat_values = np.array(list(ibeacon_rssi[target_ibeacon].values()))[:, 0]\nfig5 = visualize_heatmap(heat_positions, heat_values, floor_plan_filename, width_meter, height_meter, colorbar_title='dBm', title=f'iBeacon: {target_ibeacon} RSSI', show=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#視覺化site: 5a0546857ecc773753327266, floor:B1 所有training set內收集的wifi數量\nwifi_counts = extract_wifi_count(mwi_datas)\nheat_positions = np.array(list(wifi_counts.keys()))\nheat_values = np.array(list(wifi_counts.values()))\n# filter out positions that no wifi detected\nmask = heat_values != 0\nheat_positions = heat_positions[mask]\nheat_values = heat_values[mask]\nfig6 = visualize_heatmap(heat_positions, heat_values, floor_plan_filename, width_meter, height_meter, colorbar_title='number', title=f'Wifi Count', show=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"'''\n#Model example\ndata, label = location_sensor_filter(example)\nindices = np.random.permutation(data.shape[1])\ndata = data[:, indices]\nlabel = label[:, indices]\ndev_x = data[:, -200:]\ndev_y = label[:, -200:]\ntrain_x = data[:, :-200]\ntrain_y = label[:, :-200]\nprint(f'Train_x: {train_x.shape}')\nprint(f'Train_y: {train_y.shape}')\nprint(f'Dev_x: {dev_x.shape}')\nprint(f'Dev_y: {dev_y.shape}')\nmodel = location_prediction_model(train_x.shape[0])\nmodel.compile(optimizer='adam', loss='mae')\nhistory = model.fit(train_x.T, train_y.T, batch_size=64, epochs = 10, validation_data = (dev_x.T, dev_y.T), verbose=0, shuffle=True)\n\nplt.figure(figsize=(20, 6))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Dev'], loc='upper left')\nplt.show()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#訓練模型\n#用Glob module回傳所有train/test檔案路徑到串列變數中\ntrain_paths = glob.glob('../input/indoor-location-navigation/train/*/*/*')\ntest_paths = glob.glob('../input/indoor-location-navigation/test/*')\nsite_paths = glob.glob('../input/indoor-location-navigation/metadata/*')\nsubmission = pd.read_csv('../input/indoor-location-navigation/sample_submission.csv')\nsubmission_site_dic = submission_to_dic(submission)\nprint(\"No. Files in Train: {:,}\".format(len(train_paths)), \"\\n\" +\n      \"No. Files in Test: {:,}\".format(len(test_paths)), \"\\n\" +\n      \"Total Sites (metadata): {:,}\".format(len(site_paths)))\n\n#預測floor使用的函數執行時間過長，將運算結果存到.json檔供下次讀取\n#submission_site_paths = submission_to_submission_paths(submission_site_dic)\n#max_rssi_dic = site_floor_bssid_rssi_dic(submission_site_paths)\n#with open('max_rssi_dic.json', 'w', encoding='utf-8') as f:\n#    json.dump(max_rssi_dic, f)\n\nwith open('../input/d/evanhsiao/indoor-location-navigation/max_rssi_dic.json', 'r', encoding='utf-8') as f:\n    max_rssi_dic = json.load(f)\n'''\n#訓練模型\nmodel = location_prediction_model(train_x.shape[0])\nmodel.compile(optimizer='adam', loss='mae')\n\ntrained_model = location_training(model, np.random.choice(train_paths, 1000))\n'''\n#測試floor detect在training data的表現\nacc = {}\nfor site in submission_site_dic:\n    score = 0\n    path_datas = glob.glob(f'../input/indoor-location-navigation/train/{site}/*/*')\n    n = len(path_datas)\n    for path in path_datas:\n        ans = path.split('/')[-2]\n        if ans == '1F' or ans == 'F1':\n            ans = 0\n        elif ans == '2F' or ans == 'F2':\n            ans = 1\n        elif ans == '3F' or ans == 'F3':\n            ans = 2\n        elif ans == '4F' or ans == 'F4':\n            ans = 3\n        elif ans == '5F' or ans == 'F5':\n            ans = 4\n        elif ans == '6F' or ans == 'F6':\n            ans = 5\n        elif ans == '7F' or ans == 'F7':\n            ans = 6\n        elif ans == '8F' or ans == 'F8':\n            ans = 7\n        elif ans == 'B1' or ans == '1B':\n            ans = -1\n        elif ans == 'B2' or ans == '2B':\n            ans = -2\n        elif ans == 'B3' or ans == '3B':\n            ans = -3\n        elif ans == 'B4' or ans == '4B':\n            ans = -4                 \n        test_data = read_data_file(path)\n        F = floor_detect(test_data, site, max_rssi_dic)\n        if F == ans:\n            score += 1\n    acc[site] = score/n\nacc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n#預測結果並將結果更新到submission.csv檔\nfor site, path_dic in submission_site_dic.items():\n    for path, timesteps in path_dic.items():\n        path_data = f'../input/indoor-location-navigation/test/{path}.txt'\n        test_data = read_data_file(path_data)\n        F = floor_detect(test_data, site, max_rssi_dic)\n        test_x = test_data_to_test_x(test_data)\n        predictions = trained_model.predict(test_x.T[:, 1:])\n        predictions_with_timestep = np.concatenate((test_x.T[:,0:1], predictions), axis=1)\n        for timestep in timesteps:\n            target = site + '_' + path + '_' + timestep\n            int_timestep = int(timestep)\n            if int_timestep < predictions_with_timestep[-1, 0]:\n                index = np.where(predictions_with_timestep[:, 0] > int_timestep)[0][0]\n                if index == 0:\n                    location = predictions_with_timestep[0, 1:]\n                    vector = predictions_with_timestep[1, 1:] - predictions_with_timestep[0, 1:]\n                    location -= vector * (predictions_with_timestep[0,0] - int_timestep)/(predictions_with_timestep[1,0] - predictions_with_timestep[0,0])\n                    submission.loc[submission['site_path_timestamp'] == target, 'x'] = location[0]\n                    submission.loc[submission['site_path_timestamp'] == target, 'y'] = location[1]\n                    submission.loc[submission['site_path_timestamp'] == target, 'floor'] = F\n                else:\n                    location = predictions_with_timestep[index-1, 1:]\n                    vector = predictions_with_timestep[index, 1:] - predictions_with_timestep[index-1, 1:]\n                    location += vector * (int_timestep - predictions_with_timestep[index-1,0])/(predictions_with_timestep[index,0] - predictions_with_timestep[index-1,0])\n                    submission.loc[submission['site_path_timestamp'] == target, 'x'] = location[0]\n                    submission.loc[submission['site_path_timestamp'] == target, 'y'] = location[1]\n                    submission.loc[submission['site_path_timestamp'] == target, 'floor'] = F\n            else:\n                location = predictions_with_timestep[-1, 1:]\n                vector = predictions_with_timestep[-1, 1:] - predictions_with_timestep[-2, 1:]\n                location += vector * (int_timestep - predictions_with_timestep[index-1,0])/(predictions_with_timestep[-1,0] - predictions_with_timestep[index-2,0])\n                submission.loc[submission['site_path_timestamp'] == target, 'x'] = location[0]\n                submission.loc[submission['site_path_timestamp'] == target, 'y'] = location[1]\n                submission.loc[submission['site_path_timestamp'] == target, 'floor'] = F\nsubmission\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nsubmission.to_csv('20210309_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}